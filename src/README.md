
# ðŸ“˜ Overview of ``/src``

This branch includes:
- LoRA fine-tuning pipeline using **PEFT + Accelerate + DeepSpeed**
- Inference benchmarking and BLEU evaluation
- Dynamic routing prototype for model selection
- Dockerized setup for reproducible experiments

---

## ðŸ§© Project Structure
```text
P10-T1 LLM Compression Trade-Off Accelerator
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ accelerate_config.yaml
â”‚   â”œâ”€â”€ deepspeed_config.json
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ train_lora.py           # LoRA fine-tuning pipeline (DeepSpeed + PEFT)
â”‚   â”‚   â”œâ”€â”€ eval_and_profile.py     # Evaluates BLEU, latency, memory, and performance
â”‚   â”‚   â”œâ”€â”€ router_demo.py          # Dynamic query router (LoRA vs base model)
â”‚   â”‚   â”œâ”€â”€ check_gpu.py            # Detects CUDA capability for compatibility checks
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ code_train.json             # Optional fine-tuning dataset (code examples)
â”‚   â””â”€â”€ code_eval_prompts.json      # Evaluation prompts for Code-BLEU testing
â”‚
â”œâ”€â”€ venv/                           # Local virtual environment (optional)
â””â”€â”€ README.md
```
